![[Pasted image 20251105201920.png]]![[Pasted image 20251105201928.png]]![[Pasted image 20251105202010.png]]
![[Pasted image 20251105202047.png]]
正负样本：感/不感兴趣
![[Pasted image 20251105202147.png]]![[Pasted image 20251105202224.png]]
将每个物品做分类，输出真实兴趣概率；选择分数较大的正样本；
![[Pasted image 20251105202728.png]]
正负样本成对训练；目标：使得损失函数小；
![[Pasted image 20251105202849.png]]损失函数：三元铰链损失；三元逻辑损失；
![[Pasted image 20251105202858.png]]![[Pasted image 20251105203001.png]]一个正样本和多个负样本；
![[Pasted image 20251105203143.png]]
交叉熵损失函数：
![[Pasted image 20260114114817.png]]
衡量两个概率分布之间的差异；
鼓励s+为1，s1-到sn-为0；
==总结==
![[Pasted image 20251105210302.png]]
![[Pasted image 20251105210608.png]]
相较于训练出embedding，为用户i计算余弦相似度得分，实时输入神经网络对于找回召回太慢；
故适用于排序模型；
在全连接网络前融合向量，是粗排/精排的模型；
[[2双塔模型正负样本选择]]
[[2双塔模型改进方法：双塔模型+自监督学习]]
